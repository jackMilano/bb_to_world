#include <ros/ros.h>
#include <cv_bridge/cv_bridge.h>
#include <geometry_msgs/Point.h>
#include <geometry_msgs/PointStamped.h>
#include <message_filters/subscriber.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <message_filters/synchronizer.h>
#include <projected_game_msgs/Pose2DStamped.h>
#include <sensor_msgs/Image.h>
#include <std_msgs/Header.h>
#include <tf/tf.h>
#include <tf/transform_listener.h>
#include <tld_msgs/BoundingBox.h>
#include <cmath> // abs, round
//#include <string> // compare

#define END_FRAME "/world"
#define MIN_CONFIDENCE 0.1f
#define __DEPRECATED


typedef tf::Stamped<tf::Vector3> StampedPoint;
typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, tld_msgs::BoundingBox>
MySyncPolicy;


void boundingBoxCallback(
    const sensor_msgs::Image::ConstPtr& depthOpticalImage,
    const tld_msgs::BoundingBox::ConstPtr& bBox,
    const std::string endFrame,
    const tf::TransformListener* transformer,
    const ros::Publisher* robotPosePub)
{
  static int seq; // Sequence number dei pacchetti da me inviati.
  //bool sameFrame = (bBox->header.frame_id.compare(depthOpticalImage->header.frame_id) == 0);

  // non inviare quando la confidenza è bassa
  if( bBox->confidence < MIN_CONFIDENCE )
  {
    ROS_INFO("Confidence is too low!");
    return;
  }

  //  if( seq < 25 )
  //  {
  //    ROS_INFO("Sono entrato: n.%d.", seq);
  //  }

  try{

    //- kinect v1: la PCL è espressa in /camera_rgb_optical_frame
    //- kinect v2: la PCL è espressa in /kinect2_head_rgb_optical_frame

    // Calcolo del centroide.

    // Vengono calcolate le coordinate del punto centrale della bounding box.
    //  - i campi della bBox corrispondono a quelli di un cv::Rect,
    //    di conseguenza 'x' e 'y' si riferiscono al vertice in alto a sinistra
    //  - kinect v1: frame della BB '/camera_rgb_optical_frame'
    //  - kinect v2: frame della BB '/kinect2_head_rgb_optical_frame'
    const float bBoxCentralPointX = bBox->x + bBox->width/2.0;
    const float bBoxCentralPointY = bBox->y + bBox->height/2.0;
    ROS_INFO("X centro BB=%.2f, Y centro BB=%.2f", bBoxCentralPointX, bBoxCentralPointY);

    // Transforma il punto 2D calcolato nel frame della Bounding Box in un punto
    //  2D calcolato nel frame della PCL.
    StampedPoint stampedPointOut;
    {
      StampedPoint stampedPointIn;
      stampedPointIn.frame_id_ = bBox->header.frame_id;
      stampedPointIn.stamp_ = bBox->header.stamp;
      stampedPointIn.setData( tf::Point(bBoxCentralPointX, bBoxCentralPointY, 0) );
      transformer->transformPoint(depthOpticalImage->header.frame_id, stampedPointIn, stampedPointOut);
    }

    ROS_INFO("centro bb %s: (%.3f, %.3f, %.3f)", depthOpticalImage->header.frame_id.c_str(), stampedPointOut.getX(), stampedPointOut.getY(), stampedPointOut.getZ());
    //
    cv_bridge::CvImageConstPtr pippo = cv_bridge::toCvShare(depthOpticalImage);
    cv::Mat cvMat = pippo->image;

    if(cvMat.rows < stampedPointOut.getY() || cvMat.cols < stampedPointOut.getX())
    {
      ROS_WARN("depth image too small");
      return;
    }

    double depth = cvMat.at<uint16_t>(stampedPointOut.getX(), stampedPointOut.getY());
    depth /= 1000;
    ROS_INFO("depth m: %.3f", depth);
    StampedPoint stampedPointNotOpt;

    std::size_t pos = depthOpticalImage->header.frame_id.find("optical_frame");
    std::string notOptFrame = depthOpticalImage->header.frame_id.substr(0, pos);
    notOptFrame = notOptFrame + "frame";
    transformer->transformPoint(notOptFrame, stampedPointOut, stampedPointNotOpt);

    ROS_INFO("centro bb %s: (%.3f, %.3f, %.3f)",notOptFrame.c_str(), stampedPointNotOpt.getX(), stampedPointNotOpt.getY(), stampedPointNotOpt.getZ());
    stampedPointNotOpt.setX(depth);

    // Conversione dal frame della PCL al frame finale (endFrame)
    StampedPoint stampedPointEnd;
    transformer->transformPoint(endFrame, stampedPointNotOpt, stampedPointEnd);

    ROS_INFO("centro bb %s: (%.3f, %.3f, %.3f)", endFrame.c_str(), stampedPointEnd.getX(), stampedPointEnd.getY(), stampedPointEnd.getZ());
    // Preparazione del msg Pose2DStamped per essere inviato
    projected_game_msgs::Pose2DStamped pose2DStampedMsg;
    pose2DStampedMsg.header.frame_id = endFrame;
    pose2DStampedMsg.header.seq = seq++;
    pose2DStampedMsg.header.stamp = depthOpticalImage->header.stamp;
    pose2DStampedMsg.pose.theta = 0.0;
    pose2DStampedMsg.pose.x = stampedPointEnd.getX();
    pose2DStampedMsg.pose.y = stampedPointEnd.getY();

    // Pubblicazione delle coordinate del punto in un topic
    robotPosePub->publish(pose2DStampedMsg);
  }
  catch(std::exception &ex){
    ROS_WARN("%s", ex.what());
  }
  return;
}

int main(int argc, char** argv)
{
  std::string endFrame;

  ros::init(argc, argv, "bb_to_world_node");

  // Check arguments
  if( argc != 2 )
  {
    fprintf(stderr, "Usage: %s <end_frame>.\n", argv[0]);
    endFrame = END_FRAME;
  }
  else
  {
    endFrame = argv[1];
  }
  ROS_INFO("endFrame = %s.", endFrame.c_str());

  ros::NodeHandle node;

  message_filters::Subscriber<sensor_msgs::Image> depthImageSub(node, "depth_image", 1);
  message_filters::Subscriber<tld_msgs::BoundingBox> bBoxSub(node, "b_box", 1);

  tf::TransformListener transformer;

  ros::Publisher robotPosePub = node.advertise<projected_game_msgs::Pose2DStamped> ("robot/pose", 1);

  message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), depthImageSub, bBoxSub);
  sync.registerCallback(boost::bind(&boundingBoxCallback, _1, _2, endFrame, &transformer, &robotPosePub));

  ros::spin();

  return 0;
}
